{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 1_Layers.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saurabhIU/Deep-Learning/blob/master/Assignment_1_Layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "cCbFx22sjGHL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import time\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "um53XWCHqOLW",
        "colab_type": "code",
        "outputId": "9f32152c-77ff-4bd8-b61e-ce10df6b447c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gaEswpHsjW1L",
        "colab_type": "code",
        "outputId": "fc13f2b4-8d7e-441e-d842-e543f7560994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/MNIST_data\", one_hot=True)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-ab2797289218>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting /tmp/data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting /tmp/data/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5UBTmBrylbBo",
        "colab_type": "code",
        "outputId": "635504d6-4af2-4072-e8d1-cfe7b37d5d2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "X_train, Y_train = mnist.train.images,mnist.train.labels\n",
        "X_test, Y_test = mnist.test.images, mnist.test.labels\n",
        "print (f'Total Training Images in Dataset {X_train.shape} , Total training label is {Y_train.shape}')\n",
        "print (f'Total Test Images in Dataset {X_test.shape} , Total test label is {Y_test.shape}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Training Images in Dataset (55000, 784) , Total training label is (55000, 10)\n",
            "Total Test Images in Dataset (10000, 784) , Total test label is (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HhjKIbfBabU1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 400\n",
        "BATCH_SIZE = tf.placeholder(tf.int64)\n",
        "TEST_BATCH_SIZE = tf.placeholder(tf.int64)\n",
        "training_dataset = tf.data.Dataset.from_tensor_slices((X_train, tf.cast(Y_train,tf.float32))).shuffle(500).repeat().batch(BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, tf.cast(Y_test,tf.float32))).batch(TEST_BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CTo5LDHradmV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "iterator = tf.data.Iterator.from_structure(training_dataset.output_types,\n",
        "                                               training_dataset.output_shapes)\n",
        "next_batch = iterator.get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_thZj4Jvaf3h",
        "colab_type": "code",
        "outputId": "21fc49c9-61d8-45f3-85bf-7974705efe11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "training_initialise = iterator.make_initializer(training_dataset)\n",
        "test_initialise = iterator.make_initializer(test_dataset)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py:358: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eZUfLv5w90xD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def nn_model(input_data):\n",
        " \n",
        "    layer1 = tf.layers.dense(input_data, 1024,activation=tf.nn.relu)\n",
        "    layer2 = tf.layers.dense(layer1, 1024,activation=tf.nn.relu)\n",
        "    layer3 = tf.layers.dense(layer2, 1024,activation=tf.nn.relu)\n",
        "    layer4 = tf.layers.dense(layer3, 1024,activation=tf.nn.relu)\n",
        "    logits = tf.layers.dense(layer4, 10)\n",
        "    \n",
        "    return logits\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "buaiCswtGyZn",
        "colab_type": "code",
        "outputId": "ae52dd22-3ada-41ad-9359-ffec208d9f58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "logits = nn_model(next_batch[0])\n",
        "cost = tf.nn.softmax_cross_entropy_with_logits_v2(labels=next_batch[1],logits=logits)\n",
        "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
        "prediction = tf.nn.softmax(logits)\n",
        "correct_prediction = tf.equal(tf.argmax(prediction, axis=1), tf.argmax(next_batch[1], axis=1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "saver = tf.train.Saver()\n",
        "save_dir = 'checkpoints/'\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-8-a893205a15ee>:3: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "Epoch: 0,training accuracy:11.460000276565552\n",
            "Epoch: 100,training accuracy:99.55999851226807\n",
            "Epoch: 200,training accuracy:99.80000257492065\n",
            "Epoch: 300,training accuracy:99.83999729156494\n",
            "Time taken for training is 32.61365270614624\n",
            "[[ 0.03193977 -0.02307326 -0.00570421 ...  0.00087848 -0.03731857\n",
            "  -0.00730554]\n",
            " [ 0.0159838  -0.0162081   0.02950235 ...  0.04505645  0.01139579\n",
            "  -0.01223834]\n",
            " [ 0.0167563   0.0205849   0.04750279 ... -0.00498389 -0.01340225\n",
            "  -0.03786916]\n",
            " ...\n",
            " [ 0.02119185  0.02110571 -0.01951301 ...  0.03759656  0.01358358\n",
            "   0.00098697]\n",
            " [ 0.05252109  0.01277238  0.04089479 ...  0.04376423 -0.01943889\n",
            "   0.02703743]\n",
            " [-0.04460179  0.04515132 -0.00706572 ...  0.03798307  0.00564744\n",
            "   0.02190816]]\n",
            "Test Accuracy is 98.41999816894531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Vkk22st6vL41",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    \n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  sess.run(training_initialise,feed_dict={BATCH_SIZE : 5000 })\n",
        "  \n",
        "  tic = time.time()\n",
        "  for i in range(EPOCHS):\n",
        "      c,_,acc = sess.run([cost, optimizer, accuracy])\n",
        "      if i % 100 == 0:\n",
        "        print(f'Epoch: {i},training accuracy:{acc * 100}')\n",
        "  toc = time.time()\n",
        "  print(f'Time taken for training is {toc-tic}')\n",
        "  saver.save(sess, save_path=save_dir)\n",
        "#   print(sess.run('dense/kernel:0'))\n",
        "  sess.run(test_initialise,feed_dict={TEST_BATCH_SIZE : 10000 })\n",
        "  print(f'Test Accuracy is {sess.run(accuracy*100)}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TKEtymTs82kX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Once you’re done with training, as a starter, do a feedforward step on your test samples, a thousand of them. Capture the output of the softmax layer, which will be a 10-dim probability vector per sample. In other words, each output dimension has 1,000 predictions corresponding to the 1,000 examples. For each 10-d output vector, find the dim with the maximum probability (which will eventually decide the class label). Plot the input image associated with that in a grid of subplots. For example, you can create a 10 × 10 grid of subplots, whose first row plots first ten input images that produced the highest probabilities for the first dim (which corresponds to “0”). Eventually, if your classification was near perfect, you’ll see ten 0’s in the first row, ten 1’s in the second, and so on.**"
      ]
    },
    {
      "metadata": {
        "id": "WCqKIyUH84z7",
        "colab_type": "code",
        "outputId": "ed6a3f6b-fbb6-47cc-f95a-f4bc1058fba3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Lets take a sample of 1000 from test set\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  sess.run(test_initialise,feed_dict={TEST_BATCH_SIZE : 1000 })\n",
        "  \n",
        "  print(f'Test Accuracy is {sess.run(accuracy*100)}')\n",
        "#   output = sess.run(prediction)\n",
        "#   print(output.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy is 11.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hNeO5EWnF21s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}