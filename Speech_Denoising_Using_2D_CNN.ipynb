{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speech Denoising Using 2D CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saurabhIU/Deep-Learning/blob/master/Speech_Denoising_Using_2D_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Lhf9zCRoZ7cx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "metadata": {
        "id": "6Sqkwr24Z8ce",
        "colab_type": "code",
        "outputId": "d69fe912-4fbd-45c8-afc4-76472e791d81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import librosa\n",
        "import librosa.display as disp\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time;\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VY_iKtq5aNv7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Data (Training Clean and Training Noisy data)"
      ]
    },
    {
      "metadata": {
        "id": "cCfKPe2taKRH",
        "colab_type": "code",
        "outputId": "940cd435-05ae-4341-b2f9-e26e35a0c656",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "s_clean, sr_clean=librosa.load('train_clean_male.wav',sr=None)\n",
        "print(f'Shape of clean signal is {s_clean.shape}')\n",
        "S_clean=librosa.stft(s_clean, n_fft=1024, hop_length=512)\n",
        "S_clean_abs = np.abs(S_clean).T\n",
        "\n",
        "s_dirty, sr_noisy=librosa.load('train_dirty_male.wav',sr=None)\n",
        "print(f'Shape of clean signal is {s_dirty.shape}')\n",
        "S_dirty=librosa.stft(s_dirty, n_fft=1024, hop_length=512)\n",
        "\n",
        "S_dirty_abs = np.abs(S_dirty).T"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of clean signal is (1258899,)\n",
            "Shape of clean signal is (1258899,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lWPOgbzOaQhS",
        "colab_type": "code",
        "outputId": "c18fa1ac-1618-45ce-f7c3-44fc3dd5e4ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(f'Shape of clean signal is {S_clean_abs.shape} and shape of noisy signal is {S_dirty_abs.shape}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of clean signal is (2459, 513) and shape of noisy signal is (2459, 513)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MLq2ve6djnk7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "metadata": {
        "id": "xBK5cP8hjq1T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_input_batch(batch_size, data, labels):\n",
        "    '''\n",
        "    Return a total of `batch_size` random samples and labels. \n",
        "    '''\n",
        "    index = np.random.choice(data.shape[0], batch_size)\n",
        "    x = [data[i] for i in (index)]\n",
        "    y = [labels[i] for i in (index)]\n",
        "    return np.asarray(x), np.asarray(y)\n",
        "  \n",
        "def flatten_layer(layer):\n",
        "  \n",
        "    # Get the shape of the input layer.\n",
        "    layer_shape = layer.get_shape()\n",
        "\n",
        "    \n",
        "    feature_num = layer_shape[1:4].num_elements()\n",
        "    \n",
        "    # Flatten\n",
        "    layer_flat = tf.reshape(layer, [-1, feature_num])\n",
        "\n",
        "    # Return flattened layer and the number of features.\n",
        "    return layer_flat, feature_num\n",
        "\n",
        "  \n",
        "# Function to create 2-D image of spectrogram\n",
        "  \n",
        "def create_2D_Image(data,image_height):\n",
        "  \n",
        "  image_width = data.shape[1]\n",
        "  number_of_images = data.shape[0] - image_height +1\n",
        "  output = np.zeros((number_of_images,image_height,image_width))\n",
        "  for i in range(number_of_images):\n",
        "    output[i,:,:] = data[i:i+20,:]\n",
        "  return output\n",
        "\n",
        "# Function to augment predicted output\n",
        "\n",
        "def augment_prediction(input):\n",
        "  augmented_mat = np.random.rand(19,513)/1000\n",
        "  return np.vstack((augmented_mat,input))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1nMgicimD_hA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare 2-D Image data out of spectrogram"
      ]
    },
    {
      "metadata": {
        "id": "Dx1DaPtrajeY",
        "colab_type": "code",
        "outputId": "255a7fb1-3785-4b2f-9a2b-ccbeb4b86742",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "image_height = 20 \n",
        "# Create Training image data\n",
        "\n",
        "\n",
        "X_train = create_2D_Image(S_dirty_abs,image_height)\n",
        "  \n",
        "\n",
        "# Create Training label data\n",
        "number_of_train_label = S_clean_abs.shape[0] - image_height +1\n",
        "Y_train = S_clean_abs[19:,:]\n",
        "\n",
        "print(f'Shape of train data is {X_train.shape} and shape of train label is {Y_train.shape}')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of train data is (2440, 20, 513) and shape of train label is (2440, 513)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fTRaTmBEXiW8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(-1,20,513,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H-YLHvXlFAzs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CNN Set-up"
      ]
    },
    {
      "metadata": {
        "id": "cwNCiBI-D8Ph",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 1500\n",
        "\n",
        "kernel_size1 = 5\n",
        "kernel_size2 = 7\n",
        "\n",
        "conv_strides = [1,2,2,1]\n",
        "max_pool_strides = [1,2,2,1]\n",
        "\n",
        "Batch_Size = 200\n",
        "\n",
        "kernel_num1 = 16\n",
        "kernel_num2 = 32\n",
        "\n",
        "fc1_size = 4500\n",
        "fc2_size = 513\n",
        "\n",
        "X = tf.placeholder(\"float\", [None,20,513,1])\n",
        "Y = tf.placeholder(\"float\", [None,513])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U8irCXU7qLK1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Weights and Biases"
      ]
    },
    {
      "metadata": {
        "id": "e0dm6ELVK1vL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "a57094e9-baee-481f-8c98-626727e1c775"
      },
      "cell_type": "code",
      "source": [
        "filters = {\n",
        "              'wl1': tf.get_variable('W1', shape=(kernel_size1,kernel_size1,1,kernel_num1), initializer=tf.initializers.he_normal()),\n",
        "              'wl2': tf.get_variable('W2', shape=(kernel_size2,kernel_size2,kernel_num1,kernel_num2), initializer=tf.initializers.he_normal()),\n",
        "              'wfc1': tf.get_variable('W4', shape=(2112,fc1_size), initializer=tf.initializers.he_normal()),\n",
        "              'wfc2': tf.get_variable('W5', shape=(fc1_size,fc2_size), initializer=tf.initializers.he_normal()),\n",
        "    \n",
        "              \n",
        "          }\n",
        "\n",
        "biases = {\n",
        "              'bl1': tf.get_variable('B1', shape=(kernel_num1), initializer=tf.initializers.he_normal()),\n",
        "              'bl2': tf.get_variable('B2', shape=(kernel_num2), initializer=tf.initializers.he_normal()),\n",
        "              'bl3': tf.get_variable('B4', shape=(fc1_size), initializer=tf.initializers.he_normal()),\n",
        "              'bl4': tf.get_variable('B5', shape=(fc2_size), initializer=tf.initializers.he_normal()),\n",
        "    \n",
        "          }"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RNDE1wk2qPyy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to build Convolution Layer "
      ]
    },
    {
      "metadata": {
        "id": "jmTEBd_uLIhQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Function to build Convolution Layer \n",
        "\n",
        "\n",
        "def build_convolutional_layer(input,filter_num,bias_num,kernel_num):\n",
        "    \n",
        "    \n",
        "    conv_layer = tf.nn.conv2d(input,filters[filter_num],strides=conv_strides,padding='SAME')\n",
        "    \n",
        "    conv_layer += biases[bias_num]\n",
        "    \n",
        "    conv_layer = tf.nn.max_pool(value=conv_layer,\n",
        "                                ksize=max_pool_strides,\n",
        "                                strides=max_pool_strides,\n",
        "                                padding='SAME')\n",
        "    \n",
        "    conv_layer = tf.nn.relu(conv_layer)\n",
        "    \n",
        "    return conv_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vJbkdoOHqS2-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Build two convolutional layers with maxpool and two fully connected layers"
      ]
    },
    {
      "metadata": {
        "id": "hvtdsW7mLLnI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv_nn(input):\n",
        "  \n",
        "  \n",
        "  layer1 = build_convolutional_layer(input,'wl1','bl1',kernel_num1)\n",
        "  print(layer1)\n",
        "  \n",
        "  layer2 = build_convolutional_layer(layer1,'wl2','bl2',kernel_num2)\n",
        "  print(layer2)\n",
        "  \n",
        "  \n",
        "  # Fully connected layer\n",
        "  layer_flat, fc_feature_num  = flatten_layer(layer2)\n",
        "  \n",
        "  print(fc_feature_num)\n",
        "  fc1 = tf.matmul(layer_flat,filters['wfc1']) + biases['bl3']\n",
        "  \n",
        "  fc1 = tf.nn.relu(fc1)\n",
        "  \n",
        "  fc2 = tf.matmul(fc1,filters['wfc2']) + biases['bl4']\n",
        "  \n",
        "  return fc2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PBxdzm3MqZ-4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define Cost and Optimizations"
      ]
    },
    {
      "metadata": {
        "id": "nf8UQMesLN9y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "e119346e-8fa2-426f-cdcf-65580b93e5a1"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "logits = conv_nn(X)\n",
        "print(logits)\n",
        "cost = tf.losses.mean_squared_error(Y,logits)\n",
        "optimizer = tf.train.AdamOptimizer().minimize(cost)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Relu:0\", shape=(?, 5, 129, 16), dtype=float32)\n",
            "Tensor(\"Relu_1:0\", shape=(?, 2, 33, 32), dtype=float32)\n",
            "2112\n",
            "Tensor(\"add_3:0\", shape=(?, 513), dtype=float32)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wC6JQCkdNeBv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train Convolutional Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "M428DAiTNb0D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "1555a055-da22-482f-c696-e1263786904e"
      },
      "cell_type": "code",
      "source": [
        "sess =  tf.Session() \n",
        "   \n",
        "sess.run(tf.global_variables_initializer())\n",
        "  \n",
        "tic = time.time()\n",
        "for i in range(EPOCHS):\n",
        "    x_batch, y_batch = get_input_batch(Batch_Size,X_train,Y_train)\n",
        "    c,_ = sess.run([cost, optimizer],feed_dict={X:x_batch, Y: y_batch})\n",
        "    if i % 100 == 0:\n",
        "      print(f'Epoch: {i},training loss:{c}')\n",
        "toc = time.time()\n",
        "print(f'Time taken for training is {toc-tic}')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0,training loss:1.1554371118545532\n",
            "Epoch: 100,training loss:0.04832402989268303\n",
            "Epoch: 200,training loss:0.025135790929198265\n",
            "Epoch: 300,training loss:0.01323155127465725\n",
            "Epoch: 400,training loss:0.007687220815569162\n",
            "Epoch: 500,training loss:0.005572779104113579\n",
            "Epoch: 600,training loss:0.004203344229608774\n",
            "Epoch: 700,training loss:0.003197616897523403\n",
            "Epoch: 800,training loss:0.0026615827810019255\n",
            "Epoch: 900,training loss:0.0022299382835626602\n",
            "Epoch: 1000,training loss:0.0024288829881697893\n",
            "Epoch: 1100,training loss:0.002103083534166217\n",
            "Epoch: 1200,training loss:0.001630069687962532\n",
            "Epoch: 1300,training loss:0.0014179139398038387\n",
            "Epoch: 1400,training loss:0.0012071490054950118\n",
            "Time taken for training is 61.290491819381714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R10SweY5k0Mu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Denoise train noisy signal by feeding it through trained network"
      ]
    },
    {
      "metadata": {
        "id": "jIbojDZGkWxk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4efc3784-9803-4203-e44c-9049eea47a12"
      },
      "cell_type": "code",
      "source": [
        "prediction = sess.run(logits,feed_dict={X: X_train, Y: Y_train})\n",
        "print(prediction.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2440, 513)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Lf9HtKx6uFP9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Augment predicted value with some silent frames to match the size of input"
      ]
    },
    {
      "metadata": {
        "id": "AVKb_KMDpVYF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "augmented_prediction = augment_prediction(prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X6nFePtJuOxE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Recover speech spectrogram"
      ]
    },
    {
      "metadata": {
        "id": "YcWiRMaQtoZT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prediction_complex = np.multiply(np.divide(S_dirty,S_dirty_abs.T),augmented_prediction.T)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Npm2JrgluYQY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Recover Time domain signal"
      ]
    },
    {
      "metadata": {
        "id": "xxsFj481trjS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prediction_timedomain = librosa.istft(prediction_complex,hop_length=512, win_length=1024)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qlw21DgkueZE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Trim down ground truth to match the size of denoised signal to calculate SNR"
      ]
    },
    {
      "metadata": {
        "id": "Lwwg82pLufBU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4948a6d2-9397-4907-9c42-ce9bafa915df"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "s_clean = s_clean[0:prediction_timedomain.size]\n",
        "s_clean.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1258496,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "vcXvOWKBuhRI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Calculate SNR"
      ]
    },
    {
      "metadata": {
        "id": "5Em1MI1aujWf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb6cc1fa-a5f9-4c35-de95-85ed51f79213"
      },
      "cell_type": "code",
      "source": [
        "SNR = 10*np.log10(np.dot(s_clean.T,s_clean)/np.dot((s_clean - prediction_timedomain).T,(s_clean - prediction_timedomain)))\n",
        "SNR"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15.956320762634277"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "8MqS4NEpulgw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load test noisy signal test_01_x.wav and test_02_x.wav. Feed their magnitude spectra to trained network"
      ]
    },
    {
      "metadata": {
        "id": "pzjlLtmeuoQb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf2384de-5276-4683-c53e-2d56202f053d"
      },
      "cell_type": "code",
      "source": [
        "test1, sr_test=librosa.load('test_x_01.wav',sr=None)\n",
        "Test1=librosa.stft(test1, n_fft=1024, hop_length=512,window=\"hann\")\n",
        "Test1_absolute = np.abs(Test1).T\n",
        "\n",
        "\n",
        "test2, sr_test=librosa.load('test_x_02.wav',sr=None)\n",
        "Test2=librosa.stft(test2, n_fft=1024, hop_length=512,window=\"hann\")\n",
        "Test2_absolute = np.abs(Test2).T\n",
        "\n",
        "print(f'Shape of Test1 is {Test1_absolute.shape} and Test2 is {Test2_absolute .shape}')\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Test1 is (142, 513) and Test2 is (380, 513)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hbfQgsXyj7Gz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test1 = create_2D_Image(Test1_absolute,image_height)\n",
        "\n",
        "X_test2 = create_2D_Image(Test2_absolute,image_height)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F6stpspjuxJI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_Test1 = X_test1.reshape(-1,20,513,1)\n",
        "\n",
        "X_Test2 = X_test2.reshape(-1,20,513,1)\n",
        "\n",
        "\n",
        "test_prediction_1 = sess.run(logits,feed_dict={X: X_Test1})\n",
        "\n",
        "test_prediction_2 = sess.run(logits,feed_dict={X: X_Test2})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bbwTywKbnsuL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Augment test predictions"
      ]
    },
    {
      "metadata": {
        "id": "ADZmUfS6nw53",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Augment prediction for Test1\n",
        "augmented_prediction_1 = augment_prediction(test_prediction_1)\n",
        "\n",
        "# Augment prediction for Test2\n",
        "augmented_prediction_2 = augment_prediction(test_prediction_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fPrr7zK7u0Q0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Recover complex valued speech spectrogram of cleaned test signals"
      ]
    },
    {
      "metadata": {
        "id": "0H245A-wux3u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test1_complex = np.multiply(np.divide(Test1,Test1_absolute.T),augmented_prediction_1.T)\n",
        "\n",
        "test2_complex = np.multiply(np.divide(Test2,Test2_absolute.T),augmented_prediction_2.T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p7XR_ixdu6L-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Recover time domain speech signal by applying inverse-STFT"
      ]
    },
    {
      "metadata": {
        "id": "jUx7RiMQu4Oe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test1_timedomain = librosa.istft(test1_complex,hop_length=512, win_length=1024,window=\"hann\")\n",
        "\n",
        "test2_timedomain = librosa.istft(test2_complex,hop_length=512, win_length=1024,window=\"hann\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nIDQEG0ru89h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Write out the cleaned speech signals"
      ]
    },
    {
      "metadata": {
        "id": "qOXFWx11u_Cn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "librosa.output.write_wav('cleaned_test1_conv2.wav', test1_timedomain, sr_test)\n",
        "\n",
        "librosa.output.write_wav('cleaned_test2_conv2.wav', test2_timedomain, sr_test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}