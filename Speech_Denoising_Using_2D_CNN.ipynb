{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speech Denoising Using 2D CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saurabhIU/Deep-Learning/blob/master/Speech_Denoising_Using_2D_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Lhf9zCRoZ7cx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "metadata": {
        "id": "6Sqkwr24Z8ce",
        "colab_type": "code",
        "outputId": "ab08a1ca-8fd6-4c07-9e0c-fa7231c7ae84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import librosa\n",
        "import librosa.display as disp\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time;\n",
        "print(tf.__version__)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VY_iKtq5aNv7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Data (Training Clean and Training Noisy data)"
      ]
    },
    {
      "metadata": {
        "id": "cCfKPe2taKRH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7b9c433d-4b7e-4717-8b15-d647975698ca"
      },
      "cell_type": "code",
      "source": [
        "s_clean, sr_clean=librosa.load('train_clean_male.wav',sr=None)\n",
        "print(f'Shape of clean signal is {s_clean.shape}')\n",
        "S_clean=librosa.stft(s_clean, n_fft=1024, hop_length=512)\n",
        "S_clean_abs = np.abs(S_clean).T\n",
        "\n",
        "s_dirty, sr_noisy=librosa.load('train_dirty_male.wav',sr=None)\n",
        "print(f'Shape of clean signal is {s_dirty.shape}')\n",
        "S_dirty=librosa.stft(s_dirty, n_fft=1024, hop_length=512)\n",
        "\n",
        "S_dirty_abs = np.abs(S_dirty).T"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of clean signal is (1258899,)\n",
            "Shape of clean signal is (1258899,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lWPOgbzOaQhS",
        "colab_type": "code",
        "outputId": "f97bc808-a6e8-4208-bc75-3f6c64e7e276",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(f'Shape of clean signal is {S_clean_abs.shape} and shape of noisy signal is {S_dirty_abs.shape}')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of clean signal is (2459, 513) and shape of noisy signal is (2459, 513)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1nMgicimD_hA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare 2-D Image data out of spectrogram"
      ]
    },
    {
      "metadata": {
        "id": "Dx1DaPtrajeY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "039b901b-7eb7-4be5-fc78-99088083a0e9"
      },
      "cell_type": "code",
      "source": [
        "# Create Training image data\n",
        "\n",
        "image_height = 20 #Height of image\n",
        "image_width = S_dirty_abs.shape[1]\n",
        "number_of_images_to_train = S_dirty_abs.shape[0] - image_height +1\n",
        "X_train = np.zeros((number_of_images_to_train,image_height,image_width))\n",
        "\n",
        "# Create Training label data\n",
        "number_of_train_label = S_clean_abs.shape[0] - image_height +1\n",
        "Y_train = np.zeros((number_of_train_label,image_height,image_width))\n",
        "\n",
        "print(f'Shape of train data is {X_train.shape} and shape of train label is {Y_train.shape}')\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of train data is (2440, 20, 513) and shape of train label is (2440, 20, 513)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZAAvnITbIPn5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H-YLHvXlFAzs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CNN Set-up"
      ]
    },
    {
      "metadata": {
        "id": "cwNCiBI-D8Ph",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Convolution layer1: kernal size = [4,4], num of filters = 16, pool patch size = [2,2], pool strides size = [2,2] \n",
        "  \n",
        "EPOCHS = 2000\n",
        "\n",
        "kernel_size1 = 4\n",
        "kernel_size2 = 2\n",
        "\n",
        "conv_strides = [1,1,1,1]\n",
        "max_pool_strides = [1,2,2,1]\n",
        "\n",
        "Batch_Size = 200\n",
        "\n",
        "kernel_num1 = 16\n",
        "kernel_num2 = 32\n",
        "\n",
        "fc1_size = 4000\n",
        "fc1_size = 513\n",
        "\n",
        "X = tf.placeholder(\"float\", [None,20,513,1])\n",
        "Y = tf.placeholder(\"float\", [None,513])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e0dm6ELVK1vL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filters = {\n",
        "              'wl1': tf.get_variable('W1', shape=(kernel_size1,kernel_size1,1,kernel_num1), initializer=tf.initializers.he_normal()),\n",
        "              'wl2': tf.get_variable('W2', shape=(kernel_size2,kernel_size2,kernel_num1,kernel_num2), initializer=tf.initializers.he_normal()),\n",
        "              'wfc1': tf.get_variable('W4', shape=(4160,fc1_size), initializer=tf.initializers.he_normal()),\n",
        "              'wfc2': tf.get_variable('W5', shape=(fc1_size,fc2_size), initializer=tf.initializers.he_normal()),\n",
        "    \n",
        "              \n",
        "          }\n",
        "\n",
        "biases = {\n",
        "              'bl1': tf.get_variable('B1', shape=(kernel_num1), initializer=tf.initializers.he_normal()),\n",
        "              'bl2': tf.get_variable('B2', shape=(kernel_num2), initializer=tf.initializers.he_normal()),\n",
        "              'bl3': tf.get_variable('B4', shape=(fc1_size), initializer=tf.initializers.he_normal()),\n",
        "              'bl4': tf.get_variable('B5', shape=(fc2_size), initializer=tf.initializers.he_normal()),\n",
        "    \n",
        "          }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jmTEBd_uLIhQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Convolution Layer \n",
        "# kernel tensor of shape [filter_width, in_channels, out_channels]\n",
        "\n",
        "def build_convolutional_layer(input,filter_num,bias_num,kernel_num):\n",
        "    \n",
        "    \n",
        "    conv_layer = tf.nn.conv2d(input,filters[filter_num],strides=conv_strides,padding='SAME')\n",
        "    \n",
        "    conv_layer += biases[bias_num]\n",
        "    \n",
        "    conv_layer = tf.nn.max_pool (value=conv_layer,\n",
        "                                  ksize=max_pool_strides,\n",
        "                                  strides=max_pool_strides,\n",
        "                                  padding='SAME')\n",
        "    \n",
        "    conv_layer = tf.nn.relu(conv_layer)\n",
        "    \n",
        "    return conv_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hvtdsW7mLLnI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv_nn(input):\n",
        "  \n",
        "  \n",
        "  layer1 = build_convolutional_layer(input,'wl1','bl1',kernel_num1)\n",
        "  print(layer1)\n",
        "  \n",
        "  layer2 = build_convolutional_layer(layer1,'wl2','bl2',kernel_num2)\n",
        "  print(layer2)\n",
        "  \n",
        "  \n",
        "  # Fully connected layer\n",
        "  layer_flat, fc_feature_num  = flatten_layer(layer3)\n",
        "  \n",
        "  print(fc_feature_num)\n",
        "  fc1 = tf.matmul(layer_flat,filters['wfc1']) + biases['bl3']\n",
        "  \n",
        "  fc1 = tf.nn.relu(fc1)\n",
        "  \n",
        "  fc2 = tf.matmul(fc1,filters['wfc2']) + biases['bl4']\n",
        "  \n",
        "  return fc2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nf8UQMesLN9y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "logits = conv_nn(X)\n",
        "cost = tf.losses.mean_squared_error(Y,logits)\n",
        "optimizer = tf.train.AdamOptimizer().minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}