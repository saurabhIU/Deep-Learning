{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speech Denoising Using 1D CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saurabhIU/Deep-Learning/blob/master/Speech_Denoising_Using_1D_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "fQetulbsZ62c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "metadata": {
        "id": "-19JMYatuIoa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0dbe0cd1-6d7f-4545-b7f0-d77bff9f192c"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import librosa\n",
        "import librosa.display as disp\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time;\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Mv3psXwM6MbH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Data (Training Clean and Training Noisy data)"
      ]
    },
    {
      "metadata": {
        "id": "HFHW2yiluIxW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "s_clean, sr_clean=librosa.load('train_clean_male.wav',sr=None)\n",
        "S_clean=librosa.stft(s_clean, n_fft=1024, hop_length=512)\n",
        "Y_train = np.abs(S_clean).T\n",
        "\n",
        "s_dirty, sr_noisy=librosa.load('train_dirty_male.wav',sr=None)\n",
        "S_dirty=librosa.stft(s_dirty, n_fft=1024, hop_length=512)\n",
        "\n",
        "X_train = np.abs(S_dirty).T\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RccTjHtoz0gw",
        "colab_type": "code",
        "outputId": "a14f9462-4b23-47d5-bb4c-af66a8c34a7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(f'Shape of clean signal is {Y_train.shape} and shape of noisy signal is {X_train.shape}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of clean signal is (2459, 513) and shape of noisy signal is (2459, 513)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3wGEiRbxd98Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "metadata": {
        "id": "zT-YFjzOeAgd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initialise_weights(shape):\n",
        "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
        "  \n",
        "def get_input_batch(batch_size, data, labels):\n",
        "    '''\n",
        "    Return a total of `batch_size` random samples and labels. \n",
        "    '''\n",
        "    index = np.random.choice(data.shape[0], batch_size)\n",
        "    x = [data[i] for i in (index)]\n",
        "    y = [labels[i] for i in (index)]\n",
        "    return np.asarray(x), np.asarray(y)\n",
        "  \n",
        "def flatten_layer(layer):\n",
        "    # Get the shape of the input layer.\n",
        "    layer_shape = layer.get_shape()\n",
        "\n",
        "    # The shape of the input layer is assumed to be:\n",
        "    # layer_shape == [num_images, img_height, img_width, num_channels]\n",
        "\n",
        "    # The number of features is: img_height * img_width * num_channels\n",
        "    # We can use a function from TensorFlow to calculate this.\n",
        "    num_features = layer_shape[1:4].num_elements()\n",
        "    \n",
        "    # Reshape the layer to [num_images, num_features].\n",
        "    # Note that we just set the size of the second dimension\n",
        "    # to num_features and the size of the first dimension to -1\n",
        "    # which means the size in that dimension is calculated\n",
        "    # so the total size of the tensor is unchanged from the reshaping.\n",
        "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
        "\n",
        "    # The shape of the flattened layer is now:\n",
        "    # [num_images, img_height * img_width * num_channels]\n",
        "\n",
        "    # Return both the flattened layer and the number of features.\n",
        "    return layer_flat, num_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pc-_IwjB6U2v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Neural Network Configuration"
      ]
    },
    {
      "metadata": {
        "id": "YvB75w0gxerZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "7e6ff9b9-ad1d-4586-a0cd-8f311db390eb"
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 400\n",
        "Batch_Size = 100\n",
        "kernel_size = 5\n",
        "\n",
        "kernel_num1 = 16\n",
        "kernel_num2 = 32\n",
        "\n",
        "fully_connected_size = 513\n",
        "\n",
        "X = tf.placeholder(\"float\", [Batch_Size,1,513,1])\n",
        "Y = tf.placeholder(\"float\", [Batch_Size,1,513,1])\n",
        "\n",
        "filters = {\n",
        "              'wl1': tf.get_variable('W1', shape=(1,kernel_size,1,kernel_num1), initializer=tf.initializers.he_normal()),\n",
        "              'wl2': tf.get_variable('W2', shape=(1,kernel_size,kernel_num1,kernel_num2), initializer=tf.initializers.he_normal()),\n",
        "              'wfc': tf.get_variable('W3', shape=(None,513), initializer=tf.initializers.he_normal()),\n",
        "    \n",
        "          }\n",
        "\n",
        "biases = {\n",
        "              'bl1': tf.get_variable('B1', shape=(kernel_num1), initializer=tf.initializers.he_normal()),\n",
        "              'bl2': tf.get_variable('B2', shape=(kernel_num2), initializer=tf.initializers.he_normal()),\n",
        "              'bl3': tf.get_variable('B3', shape=(fully_connected_size), initializer=tf.initializers.he_normal()),\n",
        "    \n",
        "          }"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RnaLE_4861lZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Convolution Layer \n",
        "# kernel tensor of shape [filter_width, in_channels, out_channels]\n",
        "\n",
        "def build_convolutional_layer(input,filter_num,bias_num,kernel_num):\n",
        "    \n",
        "    \n",
        "    conv_layer = tf.nn.conv2d(input,filters[filter_num],strides=[1, 1, 1, 1],padding='SAME')\n",
        "    \n",
        "    conv_layer += biases[bias_num]\n",
        "    \n",
        "    conv_layer = tf.nn.max_pool (value=conv_layer,\n",
        "                                  ksize=[1, 2, 2, 1],\n",
        "                                  strides=[1, 2, 2, 1],\n",
        "                                  padding='SAME')\n",
        "    \n",
        "    conv_layer = tf.nn.relu(conv_layer)\n",
        "    \n",
        "    return conv_layer\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ague7UIDTaIO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv_nn(input):\n",
        "  \n",
        "  layer1 = build_convolutional_layer(input,'wl1','bl1',kernel_num1)\n",
        "  print(layer1)\n",
        "  \n",
        "  layer2 = build_convolutional_layer(layer1,'wl2','bl2',kernel_num2)\n",
        "  print(layer2)\n",
        "  \n",
        "  # Fully connected layer\n",
        "  layer_flat, num_features  = flatten_layer(layer2)\n",
        "\n",
        "  output = tf.matmul(layer_flat,filters['W3']) + biases['bl3']\n",
        "  \n",
        "  output = tf.nn.relu(output)\n",
        "  \n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1_mW-55e7ZEH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "037ffed0-f170-4817-d3ae-0e2886fdec3c"
      },
      "cell_type": "code",
      "source": [
        "logits = conv_nn(X)\n",
        "cost = tf.losses.mean_squared_error(Y,logits)\n",
        "optimizer = tf.train.AdamOptimizer().minimize(cost)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Relu:0\", shape=(100, 1, 257, 16), dtype=float32)\n",
            "Tensor(\"Relu_1:0\", shape=(100, 1, 129, 32), dtype=float32)\n",
            "Tensor(\"Reshape:0\", shape=(100, 4128), dtype=float32)\n",
            "4128\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d0e419136f83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(labels, predictions, weights, scope, loss_collection, reduction)\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"labels must not be None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predictions must not be None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m   with ops.name_scope(scope, \"mean_squared_error\",\n\u001b[1;32m    666\u001b[0m                       (predictions, labels, weights)) as scope:\n",
            "\u001b[0;31mValueError\u001b[0m: predictions must not be None."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "2IXoaGIF7w_V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train Convolutional Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "TxbSuKhx7vgx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess =  tf.Session() \n",
        "    \n",
        "sess.run(tf.global_variables_initializer())\n",
        "  \n",
        "tic = time.time()\n",
        "for i in range(EPOCHS):\n",
        "    x_batch, y_batch = get_input_batch(Batch_Size,X_train,Y_train)\n",
        "    c,_ = sess.run([cost, optimizer],feed_dict={X: x_batch, Y: y_batch})\n",
        "    if i % 100 == 0:\n",
        "      print(f'Epoch: {i},training loss:{c}')\n",
        "toc = time.time()\n",
        "print(f'Time taken for training is {toc-tic}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6jSRztO98jEZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Denoise train noisy signal by feeding it through trained network"
      ]
    },
    {
      "metadata": {
        "id": "KCgE3BdE8mAi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prediction = sess.run(logits,feed_dict={X: X_train, Y: X_train})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pg9cOq7-80q8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Recover speech spectrogram"
      ]
    },
    {
      "metadata": {
        "id": "v6QFx7vN81i2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "prediction_complex = np.multiply(np.divide(X_train,X_absolute),prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YC9OXKka9I74",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Recover Time domain signal"
      ]
    },
    {
      "metadata": {
        "id": "ZfUMRlIF9Jwh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prediction_timedomain = librosa.istft(prediction_complex,hop_length=512, win_length=1024)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dzKwyfWo9M1M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}