{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speech Denoising Using 1D CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saurabhIU/Deep-Learning/blob/master/Speech_Denoising_Using_1D_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "fQetulbsZ62c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "metadata": {
        "id": "-19JMYatuIoa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6b0ac3c-441c-487b-ccdd-dba85364388e"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import librosa\n",
        "import librosa.display as disp\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time;\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Mv3psXwM6MbH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Data (Training Clean and Training Noisy data)"
      ]
    },
    {
      "metadata": {
        "id": "HFHW2yiluIxW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "s_clean, sr_clean=librosa.load('train_clean_male.wav',sr=None)\n",
        "S_clean=librosa.stft(s_clean, n_fft=1024, hop_length=512)\n",
        "S_clean_abs = np.abs(S_clean).T\n",
        "Y_train = S_clean_abs\n",
        "\n",
        "\n",
        "s_dirty, sr_noisy=librosa.load('train_dirty_male.wav',sr=None)\n",
        "S_dirty=librosa.stft(s_dirty, n_fft=1024, hop_length=512)\n",
        "\n",
        "S_dirty_abs = np.abs(S_dirty).T\n",
        "\n",
        "X_train = S_dirty_abs.reshape(-1,1,513,1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RccTjHtoz0gw",
        "colab_type": "code",
        "outputId": "ee53f6f5-8163-42bf-dab1-61de0bba8315",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(f'Shape of clean signal is {Y_train.shape} and shape of noisy signal is {X_train.shape}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of clean signal is (2459, 513) and shape of noisy signal is (2459, 1, 513, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3wGEiRbxd98Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "metadata": {
        "id": "zT-YFjzOeAgd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_input_batch(batch_size, data, labels):\n",
        "    '''\n",
        "    Return a total of `batch_size` random samples and labels. \n",
        "    '''\n",
        "    index = np.random.choice(data.shape[0], batch_size)\n",
        "    x = [data[i] for i in (index)]\n",
        "    y = [labels[i] for i in (index)]\n",
        "    return np.asarray(x), np.asarray(y)\n",
        "  \n",
        "def flatten_layer(layer):\n",
        "  \n",
        "    # Get the shape of the input layer.\n",
        "    layer_shape = layer.get_shape()\n",
        "\n",
        "    \n",
        "    feature_num = layer_shape[1:4].num_elements()\n",
        "    \n",
        "    # Flatten\n",
        "    layer_flat = tf.reshape(layer, [-1, feature_num])\n",
        "\n",
        "    # Return flattened layer and the number of features.\n",
        "    return layer_flat, feature_num"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pc-_IwjB6U2v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Neural Network Configuration"
      ]
    },
    {
      "metadata": {
        "id": "YvB75w0gxerZ",
        "colab_type": "code",
        "outputId": "3fb4f6f4-72d0-499b-a168-160cf690666a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 1000\n",
        "\n",
        "kernel_size1 = 8\n",
        "kernel_size2 = 16\n",
        "kernel_size3 = 32\n",
        "\n",
        "Batch_Size = 200\n",
        "\n",
        "kernel_num1 = 16\n",
        "kernel_num2 = 32\n",
        "kernel_num3 = 64\n",
        "\n",
        "fc1_size = 2000\n",
        "fc2_size = 513\n",
        "\n",
        "\n",
        "X = tf.placeholder(\"float\", [None,1,513,1])\n",
        "Y = tf.placeholder(\"float\", [None,513])\n",
        "\n",
        "\n",
        "filters = {\n",
        "              'wl1': tf.get_variable('W1', shape=(1,kernel_size1,1,kernel_num1), initializer=tf.initializers.he_normal()),\n",
        "              'wl2': tf.get_variable('W2', shape=(1,kernel_size2,kernel_num1,kernel_num2), initializer=tf.initializers.he_normal()),\n",
        "              'wl3': tf.get_variable('W3', shape=(1,kernel_size3,kernel_num2,kernel_num3), initializer=tf.initializers.he_normal()),\n",
        "              'wfc1': tf.get_variable('W4', shape=(4160,fc1_size), initializer=tf.initializers.he_normal()),\n",
        "              'wfc2': tf.get_variable('W5', shape=(fc1_size,fc2_size), initializer=tf.initializers.he_normal()),\n",
        "    \n",
        "              \n",
        "          }\n",
        "\n",
        "biases = {\n",
        "              'bl1': tf.get_variable('B1', shape=(kernel_num1), initializer=tf.initializers.he_normal()),\n",
        "              'bl2': tf.get_variable('B2', shape=(kernel_num2), initializer=tf.initializers.he_normal()),\n",
        "              'bl3': tf.get_variable('B3', shape=(kernel_num3), initializer=tf.initializers.he_normal()),\n",
        "              'bl4': tf.get_variable('B4', shape=(fc1_size), initializer=tf.initializers.he_normal()),\n",
        "              'bl5': tf.get_variable('B5', shape=(fc2_size), initializer=tf.initializers.he_normal()),\n",
        "    \n",
        "          }\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6zixeb2XztSB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Function to build one convolutional layer with max pool"
      ]
    },
    {
      "metadata": {
        "id": "RnaLE_4861lZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Convolution Layer \n",
        "\n",
        "\n",
        "def build_convolutional_layer(input,filter_num,bias_num,kernel_num):\n",
        "    \n",
        "    \n",
        "    conv_layer = tf.nn.conv2d(input,filters[filter_num],strides=[1, 1, 1, 1],padding='SAME')\n",
        "    \n",
        "    conv_layer += biases[bias_num]\n",
        "    \n",
        "    conv_layer = tf.nn.max_pool (value=conv_layer,\n",
        "                                  ksize=[1, 1, 2, 1],\n",
        "                                  strides=[1, 1, 2, 1],\n",
        "                                  padding='SAME')\n",
        "    \n",
        "    conv_layer = tf.nn.relu(conv_layer)\n",
        "    \n",
        "    return conv_layer\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XZpUQLLrz1Fe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Build CNN with three convolutional layer with maxpool and two fully connected layer"
      ]
    },
    {
      "metadata": {
        "id": "Ague7UIDTaIO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv_nn(input):\n",
        "  \n",
        "  \n",
        "  layer1 = build_convolutional_layer(input,'wl1','bl1',kernel_num1)\n",
        "  print(layer1)\n",
        "  \n",
        "  layer2 = build_convolutional_layer(layer1,'wl2','bl2',kernel_num2)\n",
        "  print(layer2)\n",
        "  \n",
        "  layer3 = build_convolutional_layer(layer2,'wl3','bl3',kernel_num2)\n",
        "  print(layer3)\n",
        "  \n",
        "  \n",
        "  # Fully connected layer\n",
        "  layer_flat, fc_feature_num  = flatten_layer(layer3)\n",
        "  \n",
        "  print(fc_feature_num)\n",
        "  fc1 = tf.matmul(layer_flat,filters['wfc1']) + biases['bl4']\n",
        "  \n",
        "  fc1 = tf.nn.relu(fc1)\n",
        "  \n",
        "  fc2 = tf.matmul(fc1,filters['wfc2']) + biases['bl5']\n",
        "  \n",
        "  return fc2\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7wxtF7Tbz_NG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define Cost function and optimizer"
      ]
    },
    {
      "metadata": {
        "id": "1_mW-55e7ZEH",
        "colab_type": "code",
        "outputId": "d8b11b78-ae1c-458b-e264-7daa4103b68d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "logits = conv_nn(X)\n",
        "cost = tf.losses.mean_squared_error(Y,logits)\n",
        "optimizer = tf.train.AdamOptimizer().minimize(cost)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Relu:0\", shape=(?, 1, 257, 16), dtype=float32)\n",
            "Tensor(\"Relu_1:0\", shape=(?, 1, 129, 32), dtype=float32)\n",
            "Tensor(\"Relu_2:0\", shape=(?, 1, 65, 64), dtype=float32)\n",
            "4160\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2IXoaGIF7w_V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train Convolutional Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "TxbSuKhx7vgx",
        "colab_type": "code",
        "outputId": "b9451ee7-c8d9-4134-d2d3-2f37f0648f70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "sess =  tf.Session() \n",
        "   \n",
        "sess.run(tf.global_variables_initializer())\n",
        "  \n",
        "tic = time.time()\n",
        "for i in range(EPOCHS):\n",
        "    x_batch, y_batch = get_input_batch(Batch_Size,X_train,Y_train)\n",
        "    c,_ = sess.run([cost, optimizer],feed_dict={X:x_batch, Y: y_batch})\n",
        "    if i % 100 == 0:\n",
        "      print(f'Epoch: {i},training loss:{c}')\n",
        "toc = time.time()\n",
        "print(f'Time taken for training is {toc-tic}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0,training loss:1.0670050382614136\n",
            "Epoch: 100,training loss:0.021850746124982834\n",
            "Epoch: 200,training loss:0.007043549790978432\n",
            "Epoch: 300,training loss:0.0040027000941336155\n",
            "Epoch: 400,training loss:0.0032290476374328136\n",
            "Epoch: 500,training loss:0.00238299323245883\n",
            "Epoch: 600,training loss:0.0019764250610023737\n",
            "Epoch: 700,training loss:0.001569435466080904\n",
            "Epoch: 800,training loss:0.0015364603605121374\n",
            "Epoch: 900,training loss:0.0015846877358853817\n",
            "Time taken for training is 25.523308753967285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6jSRztO98jEZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Denoise train noisy signal by feeding it through trained network"
      ]
    },
    {
      "metadata": {
        "id": "KCgE3BdE8mAi",
        "colab_type": "code",
        "outputId": "6a5eb192-345c-4ab2-8977-a4c9f78210ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "prediction = sess.run(logits,feed_dict={X: X_train, Y: Y_train})\n",
        "print(prediction.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2459, 513)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pg9cOq7-80q8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Recover speech spectrogram"
      ]
    },
    {
      "metadata": {
        "id": "v6QFx7vN81i2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "prediction_complex = np.multiply(np.divide(S_dirty,S_dirty_abs.T),prediction.T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YC9OXKka9I74",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Recover Time domain signal"
      ]
    },
    {
      "metadata": {
        "id": "ZfUMRlIF9Jwh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prediction_timedomain = librosa.istft(prediction_complex,hop_length=512, win_length=1024)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dzKwyfWo9M1M",
        "colab_type": "code",
        "outputId": "8b3f7bfb-4b46-4dab-a444-ec006e8e3294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(f'Size of predicted signal is {prediction_timedomain.size} and ground truth signal is {s_clean.size}')\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of predicted signal is 1258496 and ground truth signal is 1258899\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4EQ2NmSlJ2lE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Trim down ground truth to match the size of denoised signal to calculate SNR"
      ]
    },
    {
      "metadata": {
        "id": "mvwySXXPJ1uZ",
        "colab_type": "code",
        "outputId": "7ea093cc-0861-4e06-fc53-24e34f8c32bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "s_clean = s_clean[0:prediction_timedomain.size]\n",
        "s_clean.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1258496,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "WH-7U996KJZs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Calculate SNR"
      ]
    },
    {
      "metadata": {
        "id": "WW-t_y6yKD_N",
        "colab_type": "code",
        "outputId": "b81d6881-97cd-43ce-af4d-4cb8aa876bdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "SNR = 10*np.log10(np.dot(s_clean.T,s_clean)/np.dot((s_clean - prediction_timedomain).T,(s_clean - prediction_timedomain)))\n",
        "SNR"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17.903960943222046"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "dan0jRkpYTNZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load test noisy signal test_01_x.wav and feed its magnitude spectra to trained network"
      ]
    },
    {
      "metadata": {
        "id": "ruKEGc3MYUbv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test1, sr_test=librosa.load('test_x_01.wav',sr=None)\n",
        "Test1=librosa.stft(test1, n_fft=1024, hop_length=512,window=\"hann\")\n",
        "Test1_absolute = np.abs(Test1).T\n",
        "\n",
        "X_Test = Test1_absolute.reshape(-1,1,513,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mzTLyZtVYa4V",
        "colab_type": "code",
        "outputId": "71c8bdb5-2411-4616-8c2f-bb57e3da4301",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test_prediction = sess.run(logits,feed_dict={X: X_Test})\n",
        "test_prediction.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(142, 513)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "oOJvBBJeYlqH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Recover complex valued speech spectrogram of cleaned test signal"
      ]
    },
    {
      "metadata": {
        "id": "Y6eJwJXfYmgI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test1_complex = np.multiply(np.divide(Test1,Test1_absolute.T),test_prediction.T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cgK4j77kjzCk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Recover time domain speech signal by applying inverse-STFT"
      ]
    },
    {
      "metadata": {
        "id": "2f1yNIe9j0R4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test1_timedomain = librosa.istft(test1_complex,hop_length=512, win_length=1024,window=\"hann\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NUYgU6tjj7Tk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Write out the cleaned speech signal"
      ]
    },
    {
      "metadata": {
        "id": "pKuwmKGuj8BN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "librosa.output.write_wav('cleaned_test1_conv1D.wav', test1_timedomain, sr_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uqPrr9tFkKCr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load test noisy signal test_02_x.wav and feed its magnitude spectra to trained network\n"
      ]
    },
    {
      "metadata": {
        "id": "Qe6phheEkK0z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test2, sr_test=librosa.load('test_x_02.wav',sr=None)\n",
        "Test2=librosa.stft(test2, n_fft=1024, hop_length=512,window=\"hann\")\n",
        "Test2_absolute = np.abs(Test2).T\n",
        "\n",
        "X_Test_2 = Test2_absolute.reshape(-1,1,513,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_tMNQnZNkZmA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test2_prediction = sess.run(logits,feed_dict={X: X_Test_2})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W58HnTUikhWz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Recover complex valued speech spectrogram of cleaned test signal"
      ]
    },
    {
      "metadata": {
        "id": "-5bqs1CCkeS0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test2_complex = np.multiply(np.divide(Test2,Test2_absolute.T),test2_prediction.T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "biXtk21ik6Xc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Recover time domain speech signal by applying inverse-STFT"
      ]
    },
    {
      "metadata": {
        "id": "E678N2ogkpDg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test2_timedomain = librosa.istft(test2_complex,hop_length=512, win_length=1024,window=\"hann\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mckdRUCvlD3o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Write out the cleaned speech signal"
      ]
    },
    {
      "metadata": {
        "id": "ABYN8deHlCIv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "librosa.output.write_wav('cleaned_test2_conv1D.wav', test2_timedomain, sr_test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}